{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae49bcc6-bef1-4b6e-9f63-632936cb21ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-28 21:34:37,089] [WARNING] [real_accelerator.py:209:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.\n",
      "[2025-07-28 21:34:37,091] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cpu (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-28 21:34:42,369] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "Using device: cpu\n",
      "Loading base model architecture from 't5-small'...\n",
      "Loading and consolidating fine-tuned weights from 'ray_results/TorchTrainer_2025-07-28_21-03-06/TorchTrainer_c9915_00000_0_2025-07-28_21-03-07/checkpoint_000000/'...\n",
      "Processing zero checkpoint 'ray_results/TorchTrainer_2025-07-28_21-03-06/TorchTrainer_c9915_00000_0_2025-07-28_21-03-07/checkpoint_000000/global_step0'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 1/1 [00:00<00:00, 34.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected checkpoint of type zero stage ZeroStageEnum.weights, world_size: 1\n",
      "Parsing checkpoint created by deepspeed==0.17.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering sharded weights: 100%|██████████| 131/131 [00:00<00:00, 688538.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed Trainable fp32 state dict with 131 params 60506624 elements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned weights loaded successfully.\n",
      "\n",
      "Initializing model with DeepSpeed Inference Engine...\n",
      "[2025-07-28 21:34:46,652] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.3, git-hash=unknown, git-branch=unknown\n",
      "[2025-07-28 21:34:46,653] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead\n",
      "[2025-07-28 21:34:46,654] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "[2025-07-28 21:34:46,654] [INFO] [logging.py:107:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n",
      "DeepSpeed model initialized for inference.\n",
      "\n",
      "--- Loading validation data from 'wikisql/data/validation-00000-of-00001-3f1ecb1168a6a037.parquet' ---\n",
      "Loaded 8421 records, sampled 10 for inference.\n",
      "\n",
      "--- Running Inference on 10 Samples ---\n",
      "\n",
      "----- Sample 2466 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tName the play for 1976\n",
      "Ground Truth:\tSELECT Play FROM table WHERE Year = 1976\n",
      "Generated SQL:\tSELECT Play FROM table WHERE Year = 1976\n",
      "-------------------------\n",
      "\n",
      "----- Sample 34 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\twhat are all the playoffs for u.s. open cup in 1st round\n",
      "Ground Truth:\tSELECT Playoffs FROM table WHERE U.S. Open Cup = 1st Round\n",
      "Generated SQL:\tSELECT playoffs FROM table WHERE Open cup = u.s.\n",
      "-------------------------\n",
      "\n",
      "----- Sample 7849 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhat is the location of the game that has a number smaller than 2?\n",
      "Ground Truth:\tSELECT Location FROM table WHERE Game < 2\n",
      "Generated SQL:\tSELECT Location FROM table WHERE Number  2\n",
      "-------------------------\n",
      "\n",
      "----- Sample 6642 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhat is 2004, when 2005 is \"Not Tier I\"?\n",
      "Ground Truth:\tSELECT 2004 FROM table WHERE 2005 = not tier i\n",
      "Generated SQL:\tSELECT 2004 FROM table WHERE 2005 = ntei I\n",
      "-------------------------\n",
      "\n",
      "----- Sample 8281 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhich venue led to a result of 13th and had an extra of Long Race?\n",
      "Ground Truth:\tSELECT Venue FROM table WHERE Extra = long race AND Result = 13th\n",
      "Generated SQL:\tSELECT Venue FROM table WHERE Result = 13th AND Extra = long race\n",
      "-------------------------\n",
      "\n",
      "----- Sample 7129 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhat was Anders Forsbrand's score when the TO par is +4?\n",
      "Ground Truth:\tSELECT Score FROM table WHERE To par = +4 AND Player = anders forsbrand\n",
      "Generated SQL:\tSELECT Score FROM table WHERE TO par = +4\n",
      "-------------------------\n",
      "\n",
      "----- Sample 3028 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhat was the attendance of the game that had an away team of FK Mogren?\n",
      "Ground Truth:\tSELECT Attendance FROM table WHERE Guest = fk mogren\n",
      "Generated SQL:\tSELECT Attendance FROM table WHERE Away team = fk mogren\n",
      "-------------------------\n",
      "\n",
      "----- Sample 3783 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhat is the Air Date that has a 18–49 larger than 1.9, less than 7.54 viewers and a rating less than 4.9?\n",
      "Ground Truth:\tSELECT Air Date FROM table WHERE 18–49 > 1.9 AND Viewers < 7.54 AND Rating < 4.9\n",
      "Generated SQL:\tSELECT Air Date FROM table WHERE 18–49 > 1.9 AND Viewers  7.54 AND Rating  4.9\n",
      "-------------------------\n",
      "\n",
      "----- Sample 5014 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhich Avg/G is the lowest one that has a Long smaller than 47, and a Name of frank murphy, and a Gain smaller than 569?\n",
      "Ground Truth:\tSELECT MIN Avg/G FROM table WHERE Long < 47 AND Name = frank murphy AND Gain < 569\n",
      "Generated SQL:\tSELECT Avg/G FROM table WHERE Long  47 AND Name = frank murphy AND Gain  569\n",
      "-------------------------\n",
      "\n",
      "----- Sample 3996 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhich rank has 1 silver medal and more than 1 gold medal?\n",
      "Ground Truth:\tSELECT Rank FROM table WHERE Silver = 1 AND Gold > 1\n",
      "Generated SQL:\tSELECT Rank FROM table WHERE Silver = 1 AND Gold > 1\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import os\n",
    "import deepspeed\n",
    "import pandas as pd\n",
    "# Corrected import path for the checkpoint conversion utility\n",
    "from deepspeed.utils.zero_to_fp32 import get_fp32_state_dict_from_zero_checkpoint\n",
    "\n",
    "def generate_sql(instruction, user_input, model, tokenizer, device):\n",
    "    \"\"\"\n",
    "    Generates a SQL query based on an instruction and user input using the DeepSpeed-accelerated model.\n",
    "\n",
    "    Args:\n",
    "        instruction (str): The instruction for the model (e.g., \"Translate the following into a SQL query\").\n",
    "        user_input (str): The natural language input from the user.\n",
    "        model: The DeepSpeed-accelerated model engine.\n",
    "        tokenizer (PreTrainedTokenizer): The tokenizer for the model.\n",
    "        device (torch.device): The device to run inference on (e.g., 'cuda:0' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        str: The generated SQL query.\n",
    "    \"\"\"\n",
    "    # Format the input exactly as it was during training\n",
    "    prompt = f\"Instruction: {instruction}\\nInput: {user_input}\"\n",
    "\n",
    "    # Tokenize the formatted input prompt\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    ).to(device)\n",
    "\n",
    "    # Generate the output sequence using the DeepSpeed model's generate method\n",
    "    # NOTE: Removed num_beams and early_stopping as they are not supported by DeepSpeed's inference engine.\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=128\n",
    "        )\n",
    "\n",
    "    # Decode the generated token IDs back to a string\n",
    "    generated_sql = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_sql\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Configuration ---\n",
    "    \n",
    "    # The original model ID used for training.\n",
    "    model_id = \"t5-small\"\n",
    "    \n",
    "    # Path to the directory containing the 'latest' file and the 'global_step' subdirectories.\n",
    "    deepspeed_checkpoint_dir = \"ray_results/TorchTrainer_2025-07-28_21-03-06/TorchTrainer_c9915_00000_0_2025-07-28_21-03-07/checkpoint_000000/\"\n",
    "    \n",
    "    # Path to the validation data file.\n",
    "    validation_file_path = \"wikisql/data/validation-00000-of-00001-3f1ecb1168a6a037.parquet\"\n",
    "\n",
    "    # --- Device Setup ---\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # --- 1. Load Fine-Tuned Model Weights ---\n",
    "    \n",
    "    # Load the base model architecture first\n",
    "    print(f\"Loading base model architecture from '{model_id}'...\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    # Use the correct DeepSpeed utility to consolidate the sharded ZeRO-3 checkpoint in memory.\n",
    "    # The function will read the 'latest' file in the provided directory to find the correct subfolder.\n",
    "    print(f\"Loading and consolidating fine-tuned weights from '{deepspeed_checkpoint_dir}'...\")\n",
    "    state_dict = get_fp32_state_dict_from_zero_checkpoint(deepspeed_checkpoint_dir)\n",
    "    \n",
    "    # Load the consolidated state dict into the model\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(\"Fine-tuned weights loaded successfully.\")\n",
    "\n",
    "    # --- 2. Initialize Model with DeepSpeed Inference Engine ---\n",
    "    print(\"\\nInitializing model with DeepSpeed Inference Engine...\")\n",
    "    \n",
    "    # Use deepspeed.init_inference to accelerate the model with fine-tuned weights\n",
    "    ds_model = deepspeed.init_inference(\n",
    "        model=model,\n",
    "        mp_size=1,  # Number of GPUs for model parallelism (1 for single-GPU)\n",
    "        dtype=torch.float16 if torch.cuda.is_available() else torch.float32, # Match training precision\n",
    "        replace_with_kernel_inject=True  # Use DeepSpeed's custom kernels for acceleration\n",
    "    )\n",
    "    print(\"DeepSpeed model initialized for inference.\")\n",
    "    \n",
    "    # The model is already on the correct device after init_inference.\n",
    "    ds_model.eval()\n",
    "\n",
    "    # --- 3. Load Validation Data and Run Inference on Samples ---\n",
    "    print(f\"\\n--- Loading validation data from '{validation_file_path}' ---\")\n",
    "    try:\n",
    "        df = pd.read_parquet(validation_file_path)\n",
    "        # Take 10 random samples for inference. Use a random_state for reproducibility.\n",
    "        samples = df.sample(n=10, random_state=42)\n",
    "        print(f\"Loaded {len(df)} records, sampled 10 for inference.\")\n",
    "\n",
    "        print(\"\\n--- Running Inference on 10 Samples ---\")\n",
    "        for index, row in samples.iterrows():\n",
    "            instruction = str(row.get('instruction', ''))\n",
    "            user_input = str(row.get('input', ''))\n",
    "            ground_truth_sql = str(row.get('output', ''))\n",
    "\n",
    "            print(f\"\\n----- Sample {index + 1} -----\")\n",
    "            print(f\"Instruction:\\t{instruction}\")\n",
    "            print(f\"Input:\\t\\t{user_input}\")\n",
    "            print(f\"Ground Truth:\\t{ground_truth_sql}\")\n",
    "\n",
    "            # Generate the SQL query\n",
    "            generated_sql = generate_sql(instruction, user_input, ds_model, tokenizer, device)\n",
    "\n",
    "            print(f\"Generated SQL:\\t{generated_sql}\")\n",
    "            print(\"-\" * 25)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Validation file not found at '{validation_file_path}'. Please check the path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the validation file: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d1e623-6f6e-4972-a3f7-e574b9e4dad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading base model and tokenizer from 't5-small'...\n",
      "Base model loaded successfully.\n",
      "\n",
      "--- Loading validation data from 'wikisql/data/validation-00000-of-00001-3f1ecb1168a6a037.parquet' ---\n",
      "Loaded 8421 records, sampled 10 for inference.\n",
      "\n",
      "--- Running Inference on 10 Samples (Base Model) ---\n",
      "\n",
      "----- Sample 2466 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tName the play for 1976\n",
      "Ground Truth:\tSELECT Play FROM table WHERE Year = 1976\n",
      "Generated SQL:\tthe play for 1976.\n",
      "-------------------------\n",
      "\n",
      "----- Sample 34 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\twhat are all the playoffs for u.s. open cup in 1st round\n",
      "Ground Truth:\tSELECT Playoffs FROM table WHERE U.S. Open Cup = 1st Round\n",
      "Generated SQL:\t: what are all the playoffs for u.s. open cup in 1st round?\n",
      "-------------------------\n",
      "\n",
      "----- Sample 7849 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhat is the location of the game that has a number smaller than 2?\n",
      "Ground Truth:\tSELECT Location FROM table WHERE Game < 2\n",
      "Generated SQL:\t: What is the location of the game that has a number smaller than 2?\n",
      "-------------------------\n",
      "\n",
      "----- Sample 6642 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhat is 2004, when 2005 is \"Not Tier I\"?\n",
      "Ground Truth:\tSELECT 2004 FROM table WHERE 2005 = not tier i\n",
      "Generated SQL:\tInstruktion: Translate the following into a SQL query Input: What is 2004 when \"Not Tier I\"?\n",
      "-------------------------\n",
      "\n",
      "----- Sample 8281 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhich venue led to a result of 13th and had an extra of Long Race?\n",
      "Ground Truth:\tSELECT Venue FROM table WHERE Extra = long race AND Result = 13th\n",
      "Generated SQL:\t: Which venue led to a result of 13th and had an extra Long Race?\n",
      "-------------------------\n",
      "\n",
      "----- Sample 7129 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhat was Anders Forsbrand's score when the TO par is +4?\n",
      "Ground Truth:\tSELECT Score FROM table WHERE To par = +4 AND Player = anders forsbrand\n",
      "Generated SQL:\tInstruction: Translate the following into a SQL query Input: What was Anders Forsbrand's score when the TO par is +4?\n",
      "-------------------------\n",
      "\n",
      "----- Sample 3028 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhat was the attendance of the game that had an away team of FK Mogren?\n",
      "Ground Truth:\tSELECT Attendance FROM table WHERE Guest = fk mogren\n",
      "Generated SQL:\tto translate the following into a SQL query Input: What was attendance of the game that had an away team of FK Mogren?\n",
      "-------------------------\n",
      "\n",
      "----- Sample 3783 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhat is the Air Date that has a 18–49 larger than 1.9, less than 7.54 viewers and a rating less than 4.9?\n",
      "Ground Truth:\tSELECT Air Date FROM table WHERE 18–49 > 1.9 AND Viewers < 7.54 AND Rating < 4.9\n",
      "Generated SQL:\t: What is the Air Date that has a 18–49 larger than 1.9, less than 7.54 viewers and a rating less than 4.9?\n",
      "-------------------------\n",
      "\n",
      "----- Sample 5014 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhich Avg/G is the lowest one that has a Long smaller than 47, and a Name of frank murphy, and a Gain smaller than 569?\n",
      "Ground Truth:\tSELECT MIN Avg/G FROM table WHERE Long < 47 AND Name = frank murphy AND Gain < 569\n",
      "Generated SQL:\t: Which Avg/G is the lowest one that has a Long smaller than 47, and a Name of frank murphy, and a Gain smaller than 569?\n",
      "-------------------------\n",
      "\n",
      "----- Sample 3996 -----\n",
      "Instruction:\tTranslate the following into a SQL query\n",
      "Input:\t\tWhich rank has 1 silver medal and more than 1 gold medal?\n",
      "Ground Truth:\tSELECT Rank FROM table WHERE Silver = 1 AND Gold > 1\n",
      "Generated SQL:\tInstruction: Translate the following into a SQL query Input: Which rank has 1 silver medal and more than 1 gold medal?\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def generate_sql(instruction, user_input, model, tokenizer, device):\n",
    "    \"\"\"\n",
    "    Generates a SQL query based on an instruction and user input.\n",
    "\n",
    "    Args:\n",
    "        instruction (str): The instruction for the model.\n",
    "        user_input (str): The natural language input from the user.\n",
    "        model (PreTrainedModel): The Hugging Face model.\n",
    "        tokenizer (PreTrainedTokenizer): The tokenizer for the model.\n",
    "        device (torch.device): The device to run inference on.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated SQL query.\n",
    "    \"\"\"\n",
    "    # Format the input prompt\n",
    "    prompt = f\"Instruction: {instruction}\\nInput: {user_input}\"\n",
    "\n",
    "    # Tokenize the formatted input prompt\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    ).to(device)\n",
    "\n",
    "    # Generate the output sequence\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=128,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    # Decode the generated token IDs back to a string\n",
    "    generated_sql = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_sql\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Configuration ---\n",
    "    \n",
    "    # The original model ID to be used for inference.\n",
    "    model_id = \"t5-small\"\n",
    "    \n",
    "    # Path to the validation data file.\n",
    "    validation_file_path = \"wikisql/data/validation-00000-of-00001-3f1ecb1168a6a037.parquet\"\n",
    "\n",
    "    # --- Device Setup ---\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # --- 1. Load Base Model and Tokenizer ---\n",
    "    \n",
    "    # Load the base model and tokenizer directly from Hugging Face\n",
    "    print(f\"Loading base model and tokenizer from '{model_id}'...\")\n",
    "    try:\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_id).to(device)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        model.eval() # Set the model to evaluation mode\n",
    "        print(\"Base model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # --- 2. Load Validation Data and Run Inference on Samples ---\n",
    "    print(f\"\\n--- Loading validation data from '{validation_file_path}' ---\")\n",
    "    try:\n",
    "        df = pd.read_parquet(validation_file_path)\n",
    "        # Take 10 random samples for inference. Use a random_state for reproducibility.\n",
    "        samples = df.sample(n=10, random_state=42)\n",
    "        print(f\"Loaded {len(df)} records, sampled 10 for inference.\")\n",
    "\n",
    "        print(\"\\n--- Running Inference on 10 Samples (Base Model) ---\")\n",
    "        for index, row in samples.iterrows():\n",
    "            instruction = str(row.get('instruction', ''))\n",
    "            user_input = str(row.get('input', ''))\n",
    "            ground_truth_sql = str(row.get('output', ''))\n",
    "\n",
    "            print(f\"\\n----- Sample {index + 1} -----\")\n",
    "            print(f\"Instruction:\\t{instruction}\")\n",
    "            print(f\"Input:\\t\\t{user_input}\")\n",
    "            print(f\"Ground Truth:\\t{ground_truth_sql}\")\n",
    "\n",
    "            # Generate the SQL query using the base model\n",
    "            generated_sql = generate_sql(instruction, user_input, model, tokenizer, device)\n",
    "\n",
    "            print(f\"Generated SQL:\\t{generated_sql}\")\n",
    "            print(\"-\" * 25)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Validation file not found at '{validation_file_path}'. Please check the path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the validation file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39365b0-bf71-43b4-9302-6456e38c07ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
